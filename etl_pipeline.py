# -*- coding: utf-8 -*-
"""ETL_pipeline.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_bR6Oq0StF2dJSRoGLVqobYy2lU74IVP
"""

# Code for ETL operations on Country-GDP data

# Importing the required libraries
import requests
import pandas as pd
import sqlite3
import numpy as np
import datetime
from bs4 import BeautifulSoup

log_file = 'code_log.txt'
target_file = 'Largest_banks_data.csv'

def log_progress(message):
    ''' This function logs the mentioned message of a given stage of the
    code execution to a log file. Function returns nothing'''
    timestamp_format = '%Y-%m-%d %H:%M:%S'  # Year-Month-Day Hour:Minute:Second
    now = datetime.datetime.now()  # get current timestamp
    timestamp = now.strftime(timestamp_format)
    with open(log_file, "a") as f:
        f.write(timestamp + ',' + message + '\n')

url = 'https://en.wikipedia.org/wiki/List_of_largest_banks'
db_name = 'Banks.db'
table_name = 'Largest_banks'
output_path = '/home/project/Largest_banks_data.csv'
csv_path = "/home/project/exchange_rate.csv"

# Initialize DataFrame
df = pd.DataFrame(columns=["Name", "MC_USD_Billion", "MC_EUR_Billion", "MC_GBP_Billion", "MC_INR_Billion"])
count = 0
table_attribs = ["Name", "MC_USD_Billion"]
sql_connection = sqlite3.connect(db_name)

def extract(url, table_attribs):
    ''' This function aims to extract the required information from the website
    and save it to a data frame. The function returns the data frame for further processing. '''
    global df, count  # Declare as global
    html_page = requests.get(url).text
    data = BeautifulSoup(html_page, 'html.parser')
    tables = data.find_all('tbody')

    # Ensure we are using the correct table; adjusted to access the 2nd index.
    if len(tables) < 3:
        print("Not enough tables found on the page.")
        return df

    rows = tables[2].find_all('tr')

    for row in rows:
        if count < 10:
            col = row.find_all('td')
            if len(col) != 0:
                # Extract the name safely
                name = col[1].get_text(strip=True)  # Use get_text to avoid unwanted tags
                mc_usd_value = col[2].get_text(strip=True)  # Remove unwanted characters like '\n'

                # Debugging: Print the extracted values
                print(f"Extracted Name: {name}, Extracted MC_USD_Value: {mc_usd_value}")

                # Try to convert to float and handle non-numeric values
                try:
                    mc_usd_value = float(mc_usd_value.replace(',', '').replace('$', ''))  # Handle commas and dollar signs
                except ValueError:
                    print(f"Skipping non-numeric MC_USD_Value: {mc_usd_value}")  # Inform about skipped value
                    continue  # Skip this row if it contains non-numeric data

                # Create a dictionary and convert it to a DataFrame
                data_dict = {"Name": name, "MC_USD_Billion": mc_usd_value}
                df1 = pd.DataFrame(data_dict, index=[0])

                # Concatenate the new DataFrame to the main DataFrame
                df = pd.concat([df, df1], ignore_index=True)
                count += 1
        else:
            break

    return df



def transform(df, csv_path):
    '''This function accesses the CSV file for exchange rate information,
    and adds three columns to the data frame, each containing the
    transformed version of the Market Cap column into respective currencies,
    rounded to 2 decimal places.'''

    # Read the exchange rate CSV file and convert it to a dictionary
    exchange_rate_dict = pd.read_csv(csv_path).set_index('Currency').to_dict()['Rate']

    # Using list comprehension and np.round for the currency conversion
    df['MC_GBP_Billion'] = [np.round(x * exchange_rate_dict['GBP'], 2) for x in df['MC_USD_Billion']]
    df['MC_EUR_Billion'] = [np.round(x * exchange_rate_dict['EUR'], 2) for x in df['MC_USD_Billion']]
    df['MC_INR_Billion'] = [np.round(x * exchange_rate_dict['INR'], 2) for x in df['MC_USD_Billion']]

    print(f"Market capitalization of the 5th largest bank in billion EUR: {df['MC_EUR_Billion'][4]}")

    return df


def load_to_csv(df, output_path):
    ''' This function saves the final data frame as a CSV file in
    the provided path. Function returns nothing.'''
    df.to_csv(output_path, index=False)  # Ensure no index column is added

def load_to_db(df, sql_connection, table_name):
    ''' This function saves the final data frame to a database
    table with the provided name. Function returns nothing.'''
    df.to_sql(table_name, sql_connection, if_exists='replace', index=False)

def run_query(query_statement, sql_connection):
    '''
    This function runs the query on the database table and
    prints the query statement and its output on the terminal.
    Function returns nothing.
    '''
    # Print the query statement
    print(f"Running query: {query_statement}")

    cursor = sql_connection.cursor()  # Use the passed connection
    cursor.execute(query_statement)

    # Fetch all rows from the query result
    rows = cursor.fetchall()

    # Check if any rows are returned, print them if present
    if rows:
        print("Query output:")
        for row in rows:
            print(row)
    else:
        print("No results returned from the query.")

    cursor.close()


''' Here, you define the required entities and call the relevant
functions in the correct order to complete the project. Note that this
portion is not inside any function.'''

# Log the initialization of the ETL process
log_progress("Preliminaries complete. Initiating ETL process")

# Log the completion of the Extraction process
extracted_data = extract(url, table_attribs)
print(extracted_data)
log_progress("Data extraction complete. Initiating Transformation process")

# Log the completion of the Transformation process
transformed_data = transform(extracted_data, csv_path)
log_progress("Data transformation complete. Initiating Loading process")

# Log the completion of the Loading process
load_to_csv(transformed_data, output_path)
log_progress("Data saved to CSV file")

# Initiate SQLite3 connection
sql_connection = sqlite3.connect(db_name)
log_progress("SQL Connection initiated")

# Call load_to_db()
load_to_db(transformed_data, sql_connection, table_name)
log_progress("Data loaded to Database as a table, Executing queries")

# Define query_statement for running query
# Function call 1: Selecting all from the 'Largest_banks' table
query_statement_1 = "SELECT * FROM Largest_banks;"
run_query(query_statement_1, sql_connection)

# Function call 2: Calculating the average market capitalization in GBP for the largest banks
query_statement_2 = "SELECT AVG(MC_GBP_Billion) FROM Largest_banks;"
run_query(query_statement_2, sql_connection)

# Function call 3: Selecting the names of the first 5 largest banks
query_statement_3 = "SELECT Name FROM Largest_banks LIMIT 5;"
run_query(query_statement_3, sql_connection)


# Call run_query()
log_progress("Process Complete")

# Close SQLite3 connection
sql_connection.close()
log_progress("Server Connection closed")